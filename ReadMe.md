# BGE-m3模型微调项目

本项目基于公开的法律问答数据集，对BGE-m3（BAAI/bge-m3）模型进行了微调，显著提升了密集检索效果。微调后的模型在困难负样本上，前30位命中率上提升了7%。

### 🚀 一、项目亮点

- **创新负采样**: 使用Faiss构建检索向量知识库，生成高质量困难负样本
- **性能提升**: 微调后模型在密集检索任务中，困难负样本前30位命中率提升7%
- **高效训练**: 采用参数冻结策略，只微调最后10层网络
- **全面评估**: 提供完整的模型效果评估方案

  
### 📁 二、项目结构
.
├── get_hard_sample.ipynb # 困难负样本构建及原模型评估脚本

├── freeze_train_model.sh # 模型训练微调脚本

├── evaluate_newmodel.ipynb # 微调后模型效果评估脚本

└── README.md


### 三、文件说明

#### get_hard_sample.ipynb
- **功能**: 困难负样本构建脚本
- **技术**: 使用Faiss构建检索向量知识库，根据检索结果构造困难负样本
- **输入**: 原始法律问答数据集
- **输出**: 包含困难负样本的训练数据

#### freeze_train_model.sh
- **功能**: 模型训练微调脚本
- **方法**: 冻结模型部分参数，只微调最后10层
- **特点**: 参数高效的微调策略，减少训练成本

#### evaluate_newmodel.ipynb
- **功能**: 模型效果评估脚本
- **指标**: 密集检索结果的前30位命中率等评估指标
- **结果**: 微调后模型性能提升7%

#### README.md
- **功能**: 项目说明文档
- **内容**: 包含项目介绍、使用方法、实验结果等详细信息



### 四、📊 实验结果
以下是针对构造的困难负样本评估的。

| 模型版本 | Hit@10 | Hit@20 | Hit@30 | 相对提升 |
|---------|--------|--------|--------|----------|
| 原始BGE | 44.1% | 51.3% | 55.8% | - |
| **微调BGE** | **51%** | **58%** | **63%** | **+7.0%** |




###  五、🛠️ 后续优化方向
#### 当前挑战
- 📉 **数据质量**: 原始数据集存在噪声，影响模型上限
- ⚖️ **参数敏感**: 损失函数温度参数τ需要精细调优

#### 优化计划

##### 损失函数优化
- 调整NCELoss的温度参数τ

##### 模型结构改进
- 🔓 **解冻稀疏层**: 放开embedding层进行全参数微调
- 🎓 **知识蒸馏**: 使用BGEM3论文推荐的知识蒸馏
- 🏗️ **lora微调**: 使用lora微调及模型加载，简化模型部署

##### 数据增强
- 数据清洗和去噪
- 大模型样本筛选


### 🙏 致谢

- 感谢BAAI提供的BGE基座模型
- 感谢法律问答数据集的提供者
- 感谢Faiss团队提供的高效向量检索库
